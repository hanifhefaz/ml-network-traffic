{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0deddabd-538f-4df1-af88-f71a33cf6ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Sample data (replace this with your actual dataset)\n",
    "data = {\n",
    "    'Timestamp': [\n",
    "        '2025-03-10 10:00:00', '2025-03-10 10:01:00', '2025-03-10 10:02:00',\n",
    "        '2025-03-10 10:03:00', '2025-03-10 10:04:00', '2025-03-10 10:05:00'\n",
    "    ],\n",
    "    'Source IP': ['192.168.1.10'] * 6,\n",
    "    'Destination IP': ['203.0.113.5', '203.0.113.5', '203.0.113.6', \n",
    "                      '203.0.113.7', '203.0.113.6', '203.0.113.7'],\n",
    "    'Protocol': ['TCP', 'TCP', 'TCP', 'UDP', 'TCP', 'TCP'],\n",
    "    'Source Port': [54321] * 6,\n",
    "    'Destination Port': [80, 80, 443, 53, 80, 22],\n",
    "    'Packet Size (bytes)': [500, 600, 800, 100, 900, 2000],\n",
    "    'Bytes Sent': [200, 200, 500, 100, 400, 0],\n",
    "    'Bytes Received': [150, 300, 400, 50, 200, 2000],\n",
    "    'Duration (ms)': [200, 250, 300, 50, 150, 500]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert Timestamp to DateTime and drop it for modeling\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.drop(['Timestamp', 'Source IP', 'Destination IP', 'Protocol'], axis=1, inplace=True)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df)\n",
    "\n",
    "# Train Isolation Forest model\n",
    "model = IsolationForest(contamination=0.1, random_state=42)  # Adjust contamination as needed\n",
    "model.fit(X)\n",
    "\n",
    "# Save the trained model and scaler\n",
    "joblib.dump(model, 'anomaly_detection_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a967c6-329d-4871-902f-7700c02b427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source Port  Destination Port  Packet Size (bytes)  Bytes Sent  \\\n",
      "0        54321                80                  500         200   \n",
      "1        54321               443                  900         400   \n",
      "2        54321                22                 2000           0   \n",
      "\n",
      "   Bytes Received  Duration (ms) Anomaly  \n",
      "0             150            200  Normal  \n",
      "1             200            150  Normal  \n",
      "2            2000            500  Normal  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and scaler\n",
    "model = joblib.load('anomaly_detection_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Load new data (replace this with your actual data source)\n",
    "# Example CSV file: new_network_traffic.csv\n",
    "new_data = {\n",
    "    'Source Port': [54321, 54321, 54321],\n",
    "    'Destination Port': [80, 443, 22],\n",
    "    'Packet Size (bytes)': [500, 900, 2000],\n",
    "    'Bytes Sent': [200, 400, 0],\n",
    "    'Bytes Received': [150, 200, 2000],\n",
    "    'Duration (ms)': [200, 150, 500]\n",
    "}\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Standardize the new data\n",
    "X_new = scaler.transform(new_df)\n",
    "\n",
    "# Predict anomalies\n",
    "new_df['Anomaly'] = model.predict(X_new)\n",
    "new_df['Anomaly'] = np.where(new_df['Anomaly'] == -1, 'Anomaly', 'Normal')\n",
    "\n",
    "# Output results\n",
    "print(new_df)\n",
    "\n",
    "def alert_anomalies(dataframe):\n",
    "    anomalies = dataframe[dataframe['Anomaly'] == 'Anomaly']\n",
    "    if not anomalies.empty:\n",
    "        print(\"Alert! Anomalies detected:\")\n",
    "        print(anomalies)\n",
    "\n",
    "# Call the alert function\n",
    "alert_anomalies(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf2b9d-b65f-4792-8ee1-0a4f07e79dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
